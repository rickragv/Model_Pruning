{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight pruning demo\n",
    "<h3> Weight pruning demo on image classification model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "train_file = glob.glob('train/**/*.jpg')\n",
    "for i in train_file:\n",
    "    fileName = os.path.basename(i)\n",
    "    if 'dog' in i:\n",
    "        shutil.move(i,'train/dog/'+fileName)\n",
    "    else:\n",
    "        shutil.move(i,'train/cat/'+fileName)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train/'\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.25)\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "label_mode='binary')\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "label_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(input_shape=(img_height,img_width,3)):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))    \n",
    "    model.add(data_augmentation)\n",
    "    model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=layers.LeakyReLU()))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation=layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=layers.LeakyReLU()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_1 (Rescaling)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 12,942,273\n",
      "Trainable params: 12,940,801\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.6449\n",
      "Epoch 00001: val_loss improved from inf to 0.58765, saving model to weights.hdf5\n",
      "625/625 [==============================] - 214s 342ms/step - loss: 0.6920 - accuracy: 0.6449 - val_loss: 0.5877 - val_accuracy: 0.6824\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7078\n",
      "Epoch 00002: val_loss improved from 0.58765 to 0.49677, saving model to weights.hdf5\n",
      "625/625 [==============================] - 197s 315ms/step - loss: 0.5649 - accuracy: 0.7078 - val_loss: 0.4968 - val_accuracy: 0.7572\n",
      "Epoch 3/10\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7378\n",
      "Epoch 00003: val_loss improved from 0.49677 to 0.46054, saving model to weights.hdf5\n",
      "625/625 [==============================] - 138s 220ms/step - loss: 0.5286 - accuracy: 0.7379 - val_loss: 0.4605 - val_accuracy: 0.7850\n",
      "Epoch 4/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.7558\n",
      "Epoch 00004: val_loss did not improve from 0.46054\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.5009 - accuracy: 0.7559 - val_loss: 0.5436 - val_accuracy: 0.7360\n",
      "Epoch 5/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4827 - accuracy: 0.7696\n",
      "Epoch 00005: val_loss improved from 0.46054 to 0.42103, saving model to weights.hdf5\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.4831 - accuracy: 0.7695 - val_loss: 0.4210 - val_accuracy: 0.8060\n",
      "Epoch 6/10\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.4572 - accuracy: 0.7851\n",
      "Epoch 00006: val_loss did not improve from 0.42103\n",
      "625/625 [==============================] - 135s 217ms/step - loss: 0.4569 - accuracy: 0.7852 - val_loss: 0.4896 - val_accuracy: 0.7658\n",
      "Epoch 7/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.7897\n",
      "Epoch 00007: val_loss did not improve from 0.42103\n",
      "625/625 [==============================] - 136s 217ms/step - loss: 0.4475 - accuracy: 0.7897 - val_loss: 0.4245 - val_accuracy: 0.8098\n",
      "Epoch 8/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.7979\n",
      "Epoch 00008: val_loss did not improve from 0.42103\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.4358 - accuracy: 0.7977 - val_loss: 0.4762 - val_accuracy: 0.7900\n",
      "Epoch 9/10\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8228\n",
      "Epoch 00009: val_loss improved from 0.42103 to 0.38380, saving model to weights.hdf5\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3923 - accuracy: 0.8227 - val_loss: 0.3838 - val_accuracy: 0.8304\n",
      "Epoch 10/10\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8287\n",
      "Epoch 00010: val_loss improved from 0.38380 to 0.36342, saving model to weights.hdf5\n",
      "625/625 [==============================] - 138s 221ms/step - loss: 0.3810 - accuracy: 0.8288 - val_loss: 0.3634 - val_accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f95747e8208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "save_model_path = 'weights.hdf5'\n",
    "cp = keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "        train_ds,\n",
    "        steps_per_epoch=len(train_ds),\n",
    "        epochs=10,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=len(val_ds),\n",
    "callbacks=[cp,lr_reducer,earlystopper])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.840399980545044\n",
      "Validation loss:  0.36342158913612366\n"
     ]
    }
   ],
   "source": [
    "base_loss, base_acc = model.evaluate(val_ds, verbose=0)\n",
    "print(\"Validation accuracy: \", base_acc)\n",
    "print(\"Validation loss: \", base_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Weight pruning of above model<b></h2>\n",
    "    \n",
    "#https://blog.tensorflow.org/2019/05/tf-model-optimization-toolkit-pruning-API.html</n>\n",
    "\n",
    "#https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide\n",
    "    \n",
    "<h5>Weight pruning means eliminating unnecessary values in the weight tensors. We are practically setting the neural network parametersâ€™ values to zero to remove what we estimate are unnecessary connections between the layers of a neural network. This is done during the training process to allow the neural network to adapt to the changes.</h5>\n",
    "<img src='misc/neuralnetworklayersbeforeandafterpruning.png' width=\"500\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned layer:  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f95cc225320>\n",
      "pruned layer:  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f95cc21d198>\n",
      "pruned layer:  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f95cc21d6a0>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Dropout object at 0x7f95df7aa710>\n",
      "pruned layer:  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f95747f0978>\n",
      "pruned layer:  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f95c006acf8>\n",
      "pruned layer:  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f95c006ab00>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Dropout object at 0x7f95746f83c8>\n",
      "pruned layer:  <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f95cc574be0>\n",
      "pruned layer:  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f95cc55c780>\n",
      "pruned layer:  <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f95cc40acc0>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Dropout object at 0x7f95cc53d7b8>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Flatten object at 0x7f95cc5d52e8>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Dense object at 0x7f95cc35d470>\n",
      "pruned layer:  <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f95cc35d7b8>\n",
      "pruned layer:  <tensorflow.python.keras.layers.core.Dense object at 0x7f95cc35d278>\n",
      "WARNING:tensorflow:From /home/contentcreation/anaconda3/envs/tensorflow-2/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_3 (Rescaling)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_9 (None, 126, 126, 32)      1762      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 126, 126, 32)      129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 63, 63, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout_ (None, 63, 63, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 61, 61, 64)        36930     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 61, 61, 64)        257       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 30, 30, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout_ (None, 30, 30, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 28, 28, 128)       147586    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 28, 28, 128)       513       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 14, 14, 128)       1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout_ (None, 14, 14, 128)       1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 25088)             1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_6  (None, 512)               25690626  \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 512)               2049      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_7  (None, 1)                 1027      \n",
      "=================================================================\n",
      "Total params: 25,880,886\n",
      "Trainable params: 12,940,801\n",
      "Non-trainable params: 12,940,085\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "base_model =getModel()\n",
    "base_model.load_weights('weights.hdf5')\n",
    "# whole model is pruned\n",
    "def apply_pruning(layer):\n",
    "  if(\n",
    "      isinstance(layer, tf.keras.Sequential) \n",
    "      or isinstance(layer, layers.experimental.preprocessing.Rescaling)\n",
    "  ):\n",
    "    return layer\n",
    "  print(\"pruned layer: \",layer)\n",
    "  return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  \n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_pruning,\n",
    ")\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "<h3>Non Trainable params is 12,940,085 </h3>\n",
    "<h2>All layers are pruned<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/625 [..............................] - ETA: 0s - loss: 0.2457 - accuracy: 0.9062WARNING:tensorflow:From /home/contentcreation/anaconda3/envs/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "625/625 [==============================] - 141s 225ms/step - loss: 0.3991 - accuracy: 0.8181 - val_loss: 0.4186 - val_accuracy: 0.8082\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 139s 223ms/step - loss: 0.3891 - accuracy: 0.8251 - val_loss: 0.3750 - val_accuracy: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f957411dc50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "log_dir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "model_for_pruning.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model_for_pruning.fit_generator(\n",
    "        train_ds,\n",
    "        steps_per_epoch=len(train_ds),\n",
    "        epochs=2,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=len(val_ds),\n",
    "callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.8357999920845032\n",
      "Validation loss:  0.3749958276748657\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = model_for_pruning.evaluate(val_ds, verbose=0)\n",
    "print(\"Validation accuracy: \", acc1)\n",
    "print(\"Validation loss: \", loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.save_weights(\"model_all_pruning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f94f014c6a0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f94f014cd68>\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_6 (Rescaling)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_12 (None, 512)               25690626  \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_13 (None, 1)                 1027      \n",
      "=================================================================\n",
      "Total params: 25,787,845\n",
      "Trainable params: 12,940,801\n",
      "Non-trainable params: 12,847,044\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_sel =getModel()\n",
    "base_model_sel.load_weights('weights.hdf5')\n",
    "def apply_pruning_to_dense(layer):\n",
    "  if  isinstance(layer, tf.keras.layers.Dense):\n",
    "    print(layer)\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "  \n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning_selective = tf.keras.models.clone_model(\n",
    "    base_model_sel,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "model_for_pruning_selective.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "<h3>Non Trainable params is 12,847,044  </h3>\n",
    "<h2>Pruning only dense layers <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.4171 - accuracy: 0.8088 - val_loss: 0.5714 - val_accuracy: 0.7610\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 137s 219ms/step - loss: 0.4040 - accuracy: 0.8139 - val_loss: 0.4078 - val_accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f94d07a6e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning_selective.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model_for_pruning_selective.fit_generator(\n",
    "        train_ds,\n",
    "        steps_per_epoch=len(train_ds),\n",
    "        epochs=2,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=len(val_ds),\n",
    "callbacks=callbacks)\n",
    "model_for_pruning_selective.save_weights(\"model_for_pruning_selective.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.824999988079071\n",
      "Validation loss:  0.4077540934085846\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = model_for_pruning_selective.evaluate(val_ds, verbose=0)\n",
    "print(\"Validation accuracy: \", acc1)\n",
    "print(\"Validation loss: \", loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non pruned accuracy:  0.840399980545044  VS pruned accuracy:  0.8357999920845032\n",
      "Model size saving in pruned model 33 %\n",
      "Difference in accuracy of pruned model 0.0045999884605407715\n"
     ]
    }
   ],
   "source": [
    "nonPrune = os.path.getsize(\"weights.hdf5\")\n",
    "prune = os.path.getsize(\"model_all_pruning.h5\")\n",
    "print(\"Non pruned accuracy: \", base_acc ,\" VS pruned accuracy: \", acc1)\n",
    "\n",
    "print(\"Model size saving in pruned model {} %\".format( int((1 - (prune/nonPrune))*100 )))\n",
    "print(\"Difference in accuracy of pruned model {}\".format(acc1-base_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model size saving in pruned model 33 %\n",
    "# Difference in accuracy of pruned model 0.0045999884605407715\n",
    "\n",
    "<h3>An immediate benefit from this work is disk compression: sparse tensors are amenable to compression.  we can reduce the size of the model for its storage and/or transmission </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
